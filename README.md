# Forward Diffusion Process

This repository explores the forward diffusion process, a technique used to gradually add noise to an image over a series of discrete time steps. This approach is fundamental to diffusion models, which learn to generate data by reversing the diffusion process.

## Overview

The forward diffusion process transforms an image into pure noise through a sequence of steps, where Gaussian noise is added at each step. This process is a cornerstone of generative models, particularly in Denoising Diffusion Probabilistic Models (DDPM), which learn to reverse the diffusion process to generate high-quality images from noise.

### Mathematical Formulation

In the forward diffusion process, an input image \( x_0 \) is gradually diffused across \( T \) time steps. At each time step \( t \), Gaussian noise is added according to a scheduled variance \( \beta_t \). The forward diffusion process is defined by the following recursive formula:

\[
x_t = \sqrt{1 - \beta_t} \cdot x_{t-1} + \sqrt{\beta_t} \cdot \epsilon
\]

where:
- \( x_t \) represents the noisy image at time step \( t \).
- \( \beta_t \) is the noise variance at time step \( t \), which controls the amount of noise added at each step.
- \( \epsilon \sim \mathcal{N}(0, I) \) is Gaussian noise, sampled independently at each time step.

This formulation allows \( x_t \) to gradually approach a distribution of pure noise as \( t \) increases to \( T \).

### Noise Schedule

To control the diffusion process, a noise schedule \( \beta_t \) is defined as a linearly spaced array:

\[
\beta_t = \text{linspace}(\beta_{\text{start}}, \beta_{\text{end}}, T)
\]

where:
- \( \beta_{\text{start}} \) is the initial noise variance, and \( \beta_{\text{end}} \) is the final noise variance.
- \( T \) is the total number of time steps.

The noise schedule ensures a gradual increase in noise variance, allowing a smooth transition from the original image to a noisy state. 

### Visualization of Forward Diffusion

In practice, this process can be visualized as a series of images that progressively become noisier. Starting from the original image \( x_0 \), each subsequent image \( x_t \) contains an increasing amount of Gaussian noise. By the end of the process, \( x_T \) is essentially random noise, with no visible resemblance to the original image.

## Applications

The forward diffusion process is primarily used in diffusion-based generative models, such as Denoising Diffusion Probabilistic Models (DDPM). In these models, the goal is to learn the reverse processâ€”a denoising function that can iteratively remove noise from a noisy image \( x_t \) to recover the original image \( x_0 \).

These models have found success in various fields, including:
- **Image Generation**: Synthesizing realistic images from random noise.
- **Super-Resolution**: Generating high-resolution images by denoising low-resolution counterparts.
- **Data Augmentation**: Creating new samples in data-limited environments by simulating noise addition and removal.

## Theoretical Background

Diffusion models belong to a class of **latent variable models** that progressively transform data into a simple distribution, such as a Gaussian, through a series of learned transformations. In a forward diffusion process, we progressively degrade the image by adding noise, making the data distribution simpler (approaching Gaussian noise). The generative model then learns to reverse this process, transforming Gaussian noise back into a structured image.

## Summary

The forward diffusion process is an essential step in diffusion-based generative models, gradually transforming data into noise in a controlled, step-wise fashion. By learning the reverse of this process, diffusion models can generate high-quality data, offering a powerful alternative to traditional generative models.

---

This `README.md` provides an overview of the forward diffusion process, mathematical formulation, applications, and theoretical background.
